---
title: "Выявление дифференциально-экспрессируемых пептидов"
author: "Марина Варфоломеева"
output:
  html_document:
    toc: yes
bibliography:
  - "bibs/references.bib"
  - "bibs/04_packages.bib"
csl: "bibs/ecology.csl"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library("knitcitations")
cleanbib()
options("citation_format" = "pandoc")
```

# Исследовательская гипотеза. Нулевая гипотеза.

Допустим, мы хотим сравнить ХХХ у ХХХ и ХХХ. Исходя из существующих исследований и общих знаний о ХХХ мы предполагаем, что ХХХ будет различаться у ХХХ (исследовательская гипотеза). Чтобы проверить исследовательскую гипотезу, нужно сформулировать нулевую гипотезу. Обычно нулевые гипотезы постулируют отсутствие каких либо различий, т.е. в этом случае, нулевая гипотеза говорит, что ХХХ не будет различаться. 

# Тестирование статистических гипотез.

Мы проводим эксперимент (ХХХ), измеряем ХХХ [XXXXXXXXXXссылкиХХХХХХХ]. После этого рассчитываем статистику, которая позволит оценить разницу уровней ХХХ в эксперименте (например, t-критерий). Наблюдаемое в эксперименте значение статистики сравнивают со значением, которое было бы получено, если бы уровни ХХХ не различались (т.е. если нулевая гипотеза верна). Если это значение маловероятно получить, когда уровни ХХХ не различаются, то мы "отвергаем" нулевую гипотезу. Результаты нашего эксперимента говорят в пользу нашей исследовательской гипотезы.

# Ошибки при статистических тестах

# Величина эффекта

# Мощность теста


# Способы выявления дифференциально экспрессируемых пептидов.

Есть несколько способов измерить разницу экспрессии:
- Fold change
- t-тест
- непараметрическая статистика
- модификации (типа адаптивных порогов и пр.) или комбинации нескольких методов

## Fold change

Fold change (FC)- исторически первый способ оценивать дифференциальную экспрессию. В те времена, когда повторности были дороги. Считаем, что эеспрессия меняется, если между группами она сильно отличается (в 1.5 или 2 раза).

Нужно оценить, во сколько раз экспрессия в одной группе больше, чем экспрессия в другой группе. FC - это пропорция, дробь, в числителе одна группа, в знаменателе другая. Пропорции распределены несимметрично вокруг 1. Сырые данные брать неудобно. Логарифмы распределены симметрично вокруг нуля. (пример среднего значения для пропорций и логарифмов). 

Операции с логарифмами:

- $log(1) = 0$
- $log(ab) = log(a) + log(b)$
- $log(a/b) = log(a) - log(b)$ - это и есть fold change

Обычно, данные логарифмируют при помощи `log(data, base = 2)`. Тогда можно просто посчитать разницу логарифмов - это и будет fold change.

## t-тест

Чтобы проверить гипотезу $H_0:A - B = 0$, нужно знать $\sigma$. После этого можно воспользоваться t-тестом.

$a_1, a_2, ..., a_n$ и $b_1, b_2, ..., b_m$ - множества наблюдений в двух группах

$\dash A = \sum{a_i} / n$ и $\dash B = \sum{b_i} / m$ - средние значения

$s^2_a$ и $s^b_b$ - дисперсии

$t = \frac {\dash A - \dash B} {\sqrt{\frac{s^2_a}{N} + \frac{s^_b}{M}}}$ - Welch's t-test

- если большой объем выборки, то t-статистика нормально распределена
- если данные распределены нормально, то t-статистика подчиняется t-распределению при любом объеме выборки

Далее обычные действия при t-тесте. Считаем t-статистику. Считаем вероятность получить такое значение при условии, что нулевая гипотеза верна. Если эта вероятность меньше заданного уровня значимости - отвергаем нулевую гипотезу.

График, где по одной оси логарифм экспрессии в одной группе, а по другой оси - в другой.

MAplot - график, где по одной оси (A) - среднее логарифмов экспрессии, а по другой оси (M) - разница средних логарифмов экспрессии. Часто оказывается, что большая разница средних логарифмов экспрессии наблюдается у генов с низким уровнем экспрессии.

Недостатки: пептиды с небольшой дисперсией чаще окажутся достоверными, лучше работает при большом числе повторностей

## Moderated t-test

$t_{mod} = \frac {\dash A - \dash B}{s + s_o}$ 

данные для многих генов используются для оценки дисперсии

(см. ниже сравнение)

- Significance analysis of microarrays (SAM)
- limma `r citep(citation("limma"))`

## ANOVA

- Можно контролировать много факторов сразу
- Нужно неск. повторностей (я бы сказала, что не меньше 4)
- Должны выполняться условия применимости
- После дисперсионного анализа нужны пост-хоки или заранее запланированные контрасты

## Bootstrap

- Нет особенных предположений о форме распределения
- Алгоритм: Считаем t-статистику. Много раз случайным образом переставляем данные между группами и снова считаем t-статистику, чтобы получить ее распределение после случайных перестановок. Считаем уровень значимости t-статистики, как долю пермутаций в которых получилось значение t-статистики больше данного.
- Нужно разумное число повторностей (минимум 4-6), чтобы было что переставлять

### Проблемы с t-тестом: разная дисперсия экспрессии

У разных пептидов может быть разная дисперсия экспрессии. График: несколько пептидов, по оси х группы, по оси н уровень экспрессии. То же самое можно в виде боксплота, если много значений (больше 5). Каким различиям средних мы будем больше верить - там гле большая или маленькая дисперсия?

volcano plot: по оси х разница средних логарифмов экспрессии, по оси y - $-log_{10}p-value$. Граница уровня значимости на лог шкале $-log_{10}0.01 = 2$, все что выше - значимо, все что ниже - нет. Сверху, справа и слева - пептиды, которы достоверно меняют экспрессию в ту и др. сторону больше чем в заданное число раз. Внизу справа и слева - пептиды, которые сильно но недостоверно меняют экспрессию.

Если у генов разная дисперсия, то не очень хорошо использовать среднее соотношение логарифмов. Если повторностей мало - оценки дисперсии нестабильны. Другие способы оценить дисперсию:
- использовать другие гены (?)
- empirical bayesian approach
- moderated t-test
- SAM and ad-hoc procedure

### Проблемы с t-тестом: Множественные сравнения

Далее, оценили дисперсию - тестируем каждый пептид. Для каждого пептида нам нужно протестировать нулевую гипотезу $H_0: expr_a = expr_b$. Допустим, мы используем t-критерий. Считаем t-статистику для данных, сравниваем с t-распределением с заданным числом свободы, полученным  при условии, что нулевая гипотеза верна. Если наше значение t-критерия попадает в область значений, которые маловероятно получить, если нулевая гипотеза верна, то мы отвергаем нулевую гипотезу. В качестве границы будем использовать уровень значимости $\alpha = 0.05$ или $\alpha = 0.01$. Но пептидов, которые мы хотим сравнить, много. И пептиды взяты из одних и тех же проб, т.е. отдельные сравнения не являются независимыми друг от друга.

Представьте себе, что мы сравниваем экспрессию 1000 пептидов, экспрессия которых на самом деле не различается в двух группах. Т.е.$H_0$ на самом деле справедлива. По крайней мере в 50 из этих тестов будут получены $p < 0.05$, т.е. мы сделаем ошибку первого рода - найдем различия экспрессии там, где их нет. Это плохо. Слишком большое количество ошибок. Именно поэтому часто указывают не p-values, а FDR - false discovery rate.

- Число ошибок I рода на число сравнений. Per comparison error rate
- Ожидаемое число ошибок. Per family error rate
- Вероятность получить хотябы одну ошибку I рода. Family-wise error rate
- Частота ложноположительных результатов. False discovery rate, FDR

Чувствительность и специфичность?

### Варианты действий

- внести поправки в p-values, чтобы они отражали действительность. Консервативно. Много вариантов. От Борферрони до Хольма и Хохберга.
false discovery rate correction, FDR (Benjamini–Hochberg procedure,  Benjamini–Hochberg–Yekutieli procedure)
- Эмпирическая баесовская статистика или оценки Штейна (? Stein estimators). False coverage statement rate.
- не тестировать гипотезы, а использовать только разведочный анализ - для генерации гипотез, которые потом планируется проверить.

Реальное использование t-критерия затруднительно:
- если стандартные ошибки велики - недостоверно, даже если абсолютная величина различий велика - неправильные выводы
- если стандарные ошибки малы - достоверно, даже если ничтожные различия экспрессии.
- t-статистика, вычисленная на реальных данных может быть не t-распределена - неправильные выводы.
- стандартные ошибки получаются неточными при небольшом числе реплик - неправильные выводы

## Сравнение Fold change и t-статистики (Witten and Tibshirani, 2007).

Основной вывод: лучше использовать модифицированную t-статистику или fold change. Основной аргумент при выборе между разными статистиками - что важнее с биологической точки зрения - разница в экспрессии или ее изменчивость.

Списки генов полученные при помощи t-критерия и Fold change будут разными:
- Обычный t-критерий $t = \frac {\dash A - \dash B}{s}$, $t = \frac {\dash A - \dash B} {\sqrt{\frac{s^2_a}{N} + \frac{s^_b}{M}}}$. Выбирает гены, у которых небольшие SE
- $FC = {\dash A - \dash B}$ (Guo et al., 2006,  Choe
et al., 2005). Выбирает гены, у которых самая большая разница экспрессии.
- Модифицированный t-критерий (Witten, Tibshirani, 2007) $t_{mod} = \frac {\dash A - \dash B}{s + s_o}$, где $s_o$ - это константа, кот. минимизирует коэф. вариации $t_{mod}$. Выбирает гены, у которых одновременно большая разница экспрессии и небольшие SE. $s_o$ выбирается при помощи Significance Analysis of Microarrays (Tusher et al., 2001)

## Адаптивный порог для Fold change

Если при пороге отсечения 2 или 1.5 оказывается выбрано слишком большое число пептидов, можно применять "адаптивный порог" (Fukuoka et al., 2011). Спорный метод - субъективное число групп с разным пороговым уровнем экспрессии. 

Алгоритм: Нужны две технические повторности, чтобы оценить распределение шума. Нормализуем данные. Логарифмируем. Считаем соотношение экспрессий между техническими повторностями. Делим на $i$-групп по значениям нормализованной экспрессии с численностью $N_i$. (Исключаем группы где оказалось меньше 100 генов/пептидов - писали для конференции когда-то). Для каждой группы выбрать случайным образом половину генов в группе и найти для них минимальную и максимальную FC (повторить $N_i/2$ раз). Рассчитать доверительный интервал среднего максимального и минимального FC. CIupper * constant - это верхняя граница достоверности для группы, а CIlower / constant - это нижняя граница достоверности для группы. Если увеличивать constant, то должен снижаться уровень ложноположительных срабатываний. Повторить для других групп. Найденные пороги используются для сравнения тритментов.

Аналогичные методы с разными порогами отсечения: (Tsien et al., 2002b,  Draghici, 2002)

### Эмпирическая баесовская статистика.

*****

Применение: смотрим на "типичные" значения стандартных ошибок. Поскольку данные фиксированные и пептидов много, можно оценить как выглядят "типичные" стандартные ошибки у похожих пептидов.




## Ссылки

```{r include=FALSE}
write.bibtex(file="bibs/04_packages.bib")
```
