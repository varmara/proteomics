---
title: "Методы выявления дифференциально-экспрессируемых белков"
author: "Марина Варфоломеева"
output:
  html_document:
    mathjax: default
    toc: yes
    toc_depth: 3
bibliography:
  - "bibs/references.bib"
  - "bibs/04_packages.bib"
csl: "bibs/ecology.csl"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
library("knitcitations")
cleanbib()
options("citation_format" = "pandoc")


# Knitr hooks
knitr::knit_hooks$set(
  hide_button = function(before, options, envir) {
    if (is.character(options$hide_button)) {
      button_text = options$hide_button
    } else {
      button_text = "Решение"
    }
    block_label <- paste0("hide_button", options$label)
    if (before) {
      return(paste0(sep = "\n",
                   '<button class="btn btn-primary btn-sm" data-toggle="collapse" data-target="#', block_label, '"> ', button_text, ' </button>\n',
                   '<div id="', block_label, '" class="collapse">\n'))
    } else {
      return("</div><br />\n")
    }
  },
  output = function(x, options){
    x <- gsub(x, pattern = "<", replacement = "&lt;")
    x <- gsub(x, pattern = ">", replacement = "&gt;")
    paste0(
      "<pre class=\"r-output\"><code>",
      fansi::sgr_to_html(x = x, warn = TRUE, term.cap = "256"),
      # ansistrings::ansi_to_html(text = x, fullpage = FALSE),
      "</code></pre>"
    )
  }
)
```

---

В этом разделе мы поговорим о том, как делать анализ дифференциальной экспрессии в R `r citep(citation())`.

- [Код к этому занятию](04_differential_expression_analysis.R)

- Данные о протеоме жабр гребешка _Pecten maximus_ из работы Artigaud et al. 2015
    - [Prot_Br_H_T.csv](data/Prot_Br_H_T.csv)
    - [Prot_Br_H_T_factor.csv](data/Prot_Br_H_T_factor.csv)

---

# Тестирование статистических гипотез

Допустим, мы хотим сравнить уровень экспрессии белков у морских гребешков, которых содержали при разной температуре. Исходя из существующих исследований и общих знаний мы предполагаем, что уровень экспрессии некоторых белков будет различаться (это то, что мы на самом деле думаем --- __исследовательская гипотеза__). Чтобы проверить исследовательскую гипотезу, нужна __нулевая гипотеза__. Обычно нулевые гипотезы постулируют отсутствие каких либо различий. Так и в этом примере, нулевая гипотеза говорит, что уровень экспрессии не будет различаться.

Далее, мы проводим эксперимент, измеряем уровень экспрессии. После этого рассчитываем статистику, которая позволит оценить разницу уровней экспрессии в эксперименте (например, t-критерий). Наблюдаемое в эксперименте значение статистики сравнивают со значением, которое было бы получено, если бы уровни экспрессии не различались (т.е. если нулевая гипотеза верна). Если это значение маловероятно получить, когда уровни экспрессии не различаются, то мы "отвергаем" нулевую гипотезу. В таком случае, мы считаем, что результаты нашего эксперимента говорят в пользу нашей исследовательской гипотезы. 

```{r power_data, echo=FALSE, purl=FALSE, cache=TRUE}
# Power plot using ggplot2
# reworked after
# http://rpsychologist.com/creating-a-typical-textbook-illustration-of-statistical-power-using-either-ggplot-or-base-graphics/

generate_power_data <- function(m1 = 0, sd1 = 7, m2 = 3.5, sd2 = 7, alpha = 0.05, h.type = "equal"){
  # set length of tails
  min1 <- m1-sd1*4
  max1 <- m1+sd1*4
  min2 <- m2-sd2*4
  max2 <- m2+sd2*4
  # create a sequence for x axis including z.crit
  x <- seq(min(min1,min2), max(max1, max2), .01)
  # compute critical value

  switch(h.type,
         greater={
           z.crit <- qnorm(1-alpha, m1, sd1)
           z.critm <- m1 - abs(m1 - z.crit)
         },
         less={
           z.crit <- qnorm(1-alpha, m1, sd1)
           z.critm <- m1 - abs(m1 - z.crit)
         },
         equal={
           z.crit <- qnorm(1-(alpha/2), m1, sd1)
           z.critm <- m1 - abs(m1 - z.crit)
         }
  )
  x[length(x)+1] <- z.crit
  x[length(x)+1] <- z.critm
  x <- sort(x)

  # generate normal distributions
  y1 <- dnorm(x, m1, sd1)
  y2 <- dnorm(x, m2, sd2)
  # combine to data frame
  df1 <- data.frame(x = x, y = y1)
  df2 <- data.frame(x = x, y = y2)
  # compute intervals for polygons
  outside.l <- x <= z.critm
  inside <- (x >= z.critm) & (x <= z.crit)
  outside.r <- x >= z.crit

  switch(h.type,
         greater={
           # Alpha polygon
           if(m1 < m2){
             alph <- data.frame(x = x[outside.r], y = pmin(y1[outside.r], y2[outside.r]))
           } else {
             alph <- data.frame(x = x[outside.r], y = pmax(y1[outside.r], y2[outside.r]))
           }
           alph$y[alph$x == z.crit] <- 0
           # Beta polygon one-tailed
           bet <- data.frame(x = x[outside.l | inside], y = y2[outside.l | inside])
           bet$y[bet$x == z.crit] <- 0
           bet$y[bet$x == z.critm] <- 0
           # power polygon; 1-beta, one-tailed
           pwrd <- data.frame(x = x[outside.r], y = y2[outside.r])
           pwrd$y[pwrd$x == z.crit] <- 0
           alph$id <- 3
           bet$id <- 2
           pwrd$id <- 1
           alph$obj <- 3
           bet$obj <- 2
           pwrd$obj <- 1
           # combine data frames
           poly <- rbind(alph, bet, pwrd)
           poly$id <- factor(poly$id,  labels = c("power","beta","alpha"))
         },
         less={
           # Alpha polygon
           if(m1 < m2){
             alph <- data.frame(x = x[outside.l], y = pmax(y1[outside.l], y2[outside.l]))
           } else{
             alph <- data.frame(x = x[outside.l], y = pmin(y1[outside.l], y2[outside.l]))
           }
           alph$y[alph$x == z.critm] <- 0
           # Beta polygon one-tailed
           bet <- data.frame(x = x[outside.r | inside], y = y2[outside.r | inside])
           bet$y[bet$x == z.crit] <- 0
           bet$y[bet$x == z.critm] <- 0
           # power polygon; 1-beta, one-tailed
           pwrd <- data.frame(x = x[outside.l], y = y2[outside.l])
           pwrd$y[pwrd$x == z.critm] <- 0
           alph$id <- 3
           bet$id <- 2
           pwrd$id <- 1
           alph$obj <- 3
           bet$obj <- 2
           pwrd$obj <- 1
           # combine data frames
           poly <- rbind(alph, bet, pwrd)
           poly$id <- factor(poly$id,  labels = c("power","beta","alpha"))
         },
         equal={
           # alph polygon
           if(m1 < m2){
             alph.r <- data.frame(x = x[outside.r], y = pmin(y1[outside.r], y2[outside.r]))
             alph.l <- data.frame(x = x[outside.l], y = pmax(y1[outside.l], y2[outside.l]))
           } else {
             alph.r <- data.frame(x = x[outside.r], y = pmax(y1[outside.r], y2[outside.r]))
             alph.l <- data.frame(x = x[outside.l], y = pmin(y1[outside.l], y2[outside.l]))
           }
           alph.r$y[alph.r$x == z.crit] <- 0
           alph.l$y[alph.l$x == z.critm] <- 0
           # beta polygon, two-tailed
           bet <- data.frame(x = x[inside], y = y2[inside])
           bet$y[bet$x == z.crit] <- 0
           bet$y[bet$x == z.critm] <- 0
           # two power polygons, two-tailed
           pwrd.l <- data.frame(x = x[outside.l], y = y2[outside.l])
           pwrd.l$y[pwrd.l$x == z.critm] <- 0
           pwrd.r <-data.frame(x = x[outside.r], y = y2[outside.r])
           pwrd.r$y[pwrd.r$x == z.crit] <- 0
           alph.l$id <- 3
           alph.l$obj <- 5
           alph.r$id <- 3
           alph.r$obj <- 4
           bet$id <- 2
           bet$obj <-3
           pwrd.l$id <- 1
           pwrd.l$obj <- 2
           pwrd.r$id <- 1
           pwrd.r$obj <- 1
           # combine data frames
           poly <- rbind(alph.l, alph.r, bet, pwrd.l, pwrd.r)
           poly$id <- factor(poly$id,  labels = c("power","beta","alpha"))
           poly$obj <- factor(poly$obj,  labels = c("powerr","powerl", "beta", "alphar", "alphal"))
         }
  )
  return(list(df1 = df1, df2 = df2, poly = poly, m1 = m1, m2 = m2, h.type = h.type, z.crit = z.crit, z.critm = z.critm))
}

pwr_plot <- function(pwrd, alph = TRUE, bet = TRUE, power = TRUE, ann = TRUE){
  require(ggplot2)
  # initialise filter for the data
  filter <- vector(length = length(pwrd$poly$id))
  # possible values for the scale
  category <- vector()
  lbls <- vector()
  if(alph){
    filter <- pwrd$poly$id == "alpha"
    category <- c(category, "alpha")
    lbls <- c(lbls, bquote(alpha))
  }
  if(bet){
    filter <- filter | pwrd$poly$id == "beta"
    category <- c(category, "beta")
    lbls <- c(lbls, bquote(beta))
  }
  if(power){
    filter <- filter | pwrd$poly$id == "power"
    category <- c(category, "power")
    lbls <- c(lbls, bquote(1 - beta))
  }
  # define colours by type of polygon
  cols <- c("alpha" = "red", "beta" = "blue", "power" = "green")
  if(any(alph, bet, power)){
  p <- ggplot() +
    geom_line(data = pwrd$df1, aes(x, y, linetype = "H0", group = NULL, fill = NULL)) +
    geom_line(data = pwrd$df2, aes(x, y, linetype = "Ha", group = NULL, fill = NULL)) +
    geom_polygon(data = pwrd$poly[filter, ], aes(x, y, fill = id, group = obj), alpha = 0.3) +
    scale_linetype_discrete(name = "Гипотезы") +
    scale_fill_manual(values = cols, limits = category, name = "Вероятности", labels = lbls)
  } else {
    p <- ggplot() +
      geom_line(data = pwrd$df1, aes(x, y, linetype = "H0", group = NULL, fill = NULL)) +
      geom_line(data = pwrd$df2, aes(x, y, linetype = "Ha", group = NULL, fill = NULL)) +
      scale_linetype_discrete(name = "Гипотезы")
  }
  return(p)
}

dat <- generate_power_data(m1 = 0, m2 = 5, sd1 = 10, sd2 = 10, h.type = "equal")
```

При тестировании статистических гипотез возможно четыре варианта развития событий: мы можем принять верное решение (отвергнуть неправильную или принять верную $H_0$), или мы можем ошибиться --- тоже двумя разными способами. В таблице ниже показаны типы ошибок при проверке гипотез.

| 	|$H_0$ == TRUE |	$H_0$ == FALSE |
|:-----:|:-----:|:-----:|
| Отклоняем $H_0$ 	| Ошибка __I__ рода </br>Ложно-положительный результат | 	Правильно </br>Положительный результат |
| Сохраняем $H_0$ 	| Правильно </br>Отрицательный результат | Ошибка __II__ рода </br> Ложно-отрицательный результат |


```{r power_beta, echo=FALSE, purl=FALSE, fig.height=1.5, fig.width=4}
pwr_plot(pwrd = dat, alph = T, bet = T, power = F) +
  guides(fill = guide_legend(title = NULL), linetype = guide_legend(title = NULL)) +
  theme_void()
```


__Ошибки I рода__ возникают тогда, когда мы ошибочно отклоняем справедливую $H_0$, т.е. находим различия там, где их нет на самом деле. Находить различия там, где их нет --- значит множить сущности сверх необходимого. Поэтому вероятность ошибок I рода ученые договорились строго контролировать и следить, чтобы они появлялись не чаще, чем в 5% случаев. Иногда этот произвольно выбранный порог делают еще жестче --- 1%. Вероятность ошибок I рода принято обозначать $\alpha$. Это тот самый уровень значимости, с которым принято сравнивать доверительные вероятности (p-values), полученные в статистических тестах.

__Ошибки II рода__ возникают, когда мы ошибочно принимаем ложную $H_0$, т.е. не находим различий, там, где они на самом деле есть. Несмотря на то, что про ошибки II рода реже вспоминают, их не менее обидно делать. Считается допустимым, если такие ошибки возникают не чаще чем в 20% случаев. Это тоже совершенно произвольно взятый порог. Вероятность ошибок II рода принято обозначать $\beta$.

__Мощность теста__ --- это способность выявлять различия, когда они есть на самом деле. Зная $\beta$ можно вычислить вероятность того, что статистический тест обнаружит различия $Power = 1 - \beta$

```{r power, echo=FALSE, purl=FALSE, fig.height=1.5, fig.width=4}
pwr_plot(pwrd = dat, alph = T, bet = T, power = T) +
  guides(fill = guide_legend(title = NULL), linetype = guide_legend(title = NULL)) +
  theme_void()
```


Мощность любого статистического теста будет больше:

- если величина эффекта (d, величина выявляемых различий) будет больше
- если увеличить объем выборки
- если повысить уровень значимости (например, вместо $\alpha = 0.01$, взять $\alpha = 0.05$)

На примере t-критерия зависимость мощности от этих трех величин будет выглядеть так:

```{r pwr_vs_n, echo=FALSE, purl=FALSE, fig.height=3}
# Plots of power vs. sample size etc.
# Modified after http://imdevsoftware.wordpress.com/2013/01/17/255/

# Need pwr, reshape2, ggplot2 packages
gen_pwr_vs_n <- function(d = c(0.2, 0.5, 0.8), a = c(0.05, 0.01), n = 150){
  if(!require(pwr)){install.packages("pwr");library("pwr")}
  # t-TEST
  #---------------------------------
  n <- 1:n
  t.test.power.effect<-
    as.data.frame(do.call("cbind", lapply(1:length(d),function(i){
    sapply(1:length(a),function(k){
      sapply(1:length(n), function(j){
        #       paste(d[i], n[j], a[k])
        power.t.test(n = n[j],d = d[i],sig.level = a[k],power = NULL,
                     type = "two.sample")$power
      })
    })
  })))
  t.test.power.effect[is.na(t.test.power.effect)]<-0 # some powers couldn't be calculated, set these to zero
  # melt the data
  if(!require(reshape2)){install.packages("reshape2");library("reshape2")}
  measured <- length(d)*length(a)
  t.test.power.effect <- melt(t.test.power.effect, measure.vars = 1:measured)
  # fill the levels of n, a, and d
  nms <- expand.grid(size = n, sig.level = a, effect = d)
  t.test.power.effect <- cbind(t.test.power.effect, nms)
  # do-not need variable column
  t.test.power.effect <- t.test.power.effect[, -1]
  return(t.test.power.effect)
}

dat <-gen_pwr_vs_n(n = 150)
# factors
dat$sig.level <- factor(dat$sig.level, levels = c(0.01, 0.05),
                        labels = c("p = 0.01", "p = 0.05"))
dat$effect <- factor(dat$effect, levels = c(0.2, 0.3, 0.5, 0.8),
                     labels = c("d = 0.2", "d = 0.3", "d = 0.5", "d = 0.8"))

pwr.plot <-
  ggplot(data = dat, aes(x = size, y = value, color = sig.level)) +
  geom_line(size = 1.5) + 
  facet_wrap(~effect) +
  scale_colour_discrete(name = "Уровень\nзначимости") +
  labs(x = "Объем выборки", y = "Мощность") +
  ggtitle("Мощность t-теста при различной величине эффекта (d)") +
  theme_bw() +
  theme(legend.key = element_blank(),
        axis.line = element_line(colour = "black"))
pwr.plot
```




# Способы выявления дифференциально экспрессируемых белков (The Good, The Bad, and The Ugly).

Есть множество способов измерить разницу экспрессии. Вот самые распространенные:

- __fold change__ --- соотношение уровеней экспрессии. Применяется, если нет повторностей. Грубый метод оценки, т.к. не позволяет оценить статистическую значимость.
- __t-тест__ --- при небольших выборках у него малая мощность из-за неточной оценки $\sigma$.
- __Модерированный t-тест__ (с использованием Empirical Bayes) --- более мощный, чем обычный t-критерий. Позволяет точнее оценить $\sigma$ для конкретного белка, используя информацию о распределении $\sigma$ для всех белков.

# Fold change (The Ugly)

<img src="images/the_ugly1.jpg" width=300px>

__Fold change__ (FC) --- исторически первый способ оценивать дифференциальную экспрессию. Его придумали в те времена, когда делать повторности было дорого. Договорились, что будем считать, что экспрессия меняется, если ее уровень сильно отличается между группами (в 1.5 или 2 раза).

Нужно оценить, во сколько раз экспрессия в одной группе больше, чем экспрессия в другой группе. FC --- это пропорция, дробь, в числителе одна группа, в знаменателе другая.

Не надо усреднять соотношения!

Допустим, мы сравниваем уровень экспрессии до и после какого-то воздействия и у нас есть две повторности:

|                   | Повторность 1 | Повторность 2 | Среднее |
|:-----------------:|--------------:|--------------:|---------:|
| До воздействия    | $A_{1} = 1$ | $A_{2} = 10$ | $\bar{A} = 5.5$ |
| После воздействия | $B_{1} = 10$ | $B_{2} = 1$ | $\bar{B} = 5.5$ |
| | $A_{1}/B_{1} = 1/10$ | $A_{2}/B_{2} = 10/1$ |  |
| Соотношение экспрессии | $$\frac {A_{1}/B_{1}} {A_{2}/B_{2}} = \frac {1/10 + 10/1} {2} = 5.05$$ (__Неправильно!__) | | $$\bar{A} / \bar{B} = 5.5/5.5 = 0$$ (__Правильно!__) |

В первой из повторностей уровень экспрессии cнизился в 10 раз ($1/10$), а во второй --- в 10 раз вырос ($10/1$).

Если мы опрометчиво усредним эти соотношения $(1/10 + 10/1) / 2 = 5.05$, то получится, что уровень экспрессии в среднем вырос в 5 раз --- ерунда.

Правильней было бы посчитать средний уровень экспрессии до ($(1 + 10)/2 = 5.5$) и после ($(10 + 1)/2 = 5.5$), и только потом посчитать их соотношение. Тогда мы получили бы гораздо более логичный результат: на самом деле соотношение уровней экспрессии не изменилось ($5.5/5.5 = 1$).

Соотношения сырых данных экспрессии брать неудобно, потому что обычные соотношения распределены несимметрично вокруг 1. Сравните, например соотношения: $1/5 = 0.2$, $5/5 = 1$ и $5/1 = 5$.

Гораздо удобнее брать логарифм соотношения, потому что его величина распределена симметрично вокруг нуля (и тогда $log(X) = -1 * log(1/X)$). Действительно, в нашем примере будет так: $log(1/5) = -1.6$, $log(5/5) = 0$ и $log(5/1) = 1.6$.

В симметричности распределения логарифмов соотношений мы можем убедиться при помощи простой симуляции.

```{r echo=FALSE, purl=FALSE}
sim_ratios <- function(n_max){
  # Функция, которая возвращает соотношение двух 
  # случайных целых положительных чисел,
  # лежащих в пределах от 0 до nmax
  a <- sample.int(n = n_max, size = 1)
  b <- sample.int(n = n_max, size = 1)
  return(a/b)
}

# Симулируем 100 000 соотношений
set.seed(932847)
simulated_ratios <- replicate(n = 100000, sim_ratios(n_max = 20000))

# Объединяем в датафрейм сырые соотношения и их логарифмы
dat_ratios <- data.frame(
  ratio = simulated_ratios, 
  log_ratio = log2(simulated_ratios))

# рисуем боксплот
boxplot(dat_ratios, outline = F)
abline(h = 0, lty = 2, col = "red") # 0
```

Операции с логарифмами:

- $log(1) = 0$
- $log(ab) = log(a) + log(b)$
- $log(a/b) = log(a) - log(b)$ - это и есть fold change

Обычно, данные логарифмируют при помощи логарифма по основанию 2 --- `log2()`, чтобы облегчить сравнение fold change. Тогда, если экспрессия в 2 раза отличается между образцами, получится, что $log2(2x/x) = log2(2) = 1$.

Основная проблема использования fold change --- этот критерий выбирает гены, у которых самая большая разница экспрессии, но не позволяет проверить статистическую значимость различий. На самом деле, при наличии повторностей можно не использовать fold change, поскольку мы можем оценить статистическую значимость различий уровня экспрессии.

# t-тест (The Bad)

<img src="images/the_bad1.jpg" width=300px>

Чтобы проверить гипотезу $H_{0}: \bar{A} - \bar{B} = 0$, нужно оценить дисперсию в генеральной совокупности $\sigma$. После этого можно воспользоваться t-критерий.

__t-критерий__

$$t = \frac {\bar {A} - \bar {B}} {SE_{A - B}}$$

Обычный t-тест исходит из предположения, что дисперсии в группах одинаковы. Обычно, это предположение нереалистично. Мы будем использовать модификацию t-теста для разных дисперсий в группах --- т.наз. __t-критерий Велша (Welch's t-test)__. Важно, что t-тестом Уэлча можно пользоваться, даже если дисперсии равны. Он немного консервативнее, чем тест Стьюдента.

$$t = \frac {\bar {A} - \bar {B}} {\sqrt{\frac{s^{2}_{a}}{n_a} + \frac{s^{2}_{b}}{n_b}}}$$
Приблизительное число степеней свободы для t распределения можно рассчитать по уравнению Уэлча-Саттеруэйта:

$$df_{ Welch-Satterthwaite} \approx \cfrac {\bigg(\cfrac{s^2_{x_1}}{n_{x_1}} + \cfrac{s^2_{x_2}}{n_{x_2}}\bigg)^2}
{\cfrac{1}{n_{x_1} - 1}\bigg(\cfrac {s_{x_1}^2} {n_{x_1}}\bigg)^2 + \cfrac{1}{n_{x_2} - 1}\bigg(\cfrac {s_{x_2}^2} {n_{x_2}}\bigg)^2}$$


Условия применимости:

- Наблюдения должны быть независимы друг от друга.
- Выборки должны быть независимы (либо должна использоваться специальная модификация теста для зависимых выборок).
- Если большой объем выборки (N > 30), то распределение t-статистики приближается к нормальному. К сожалению, в протеомике как правило используются небольшие выборки.
- Если данные распределены нормально, то при любом объеме выборки t-статистика подчиняется t-распределению с числом степеней свободы _df_. К счастью, в логарифмической шкале значения экспрессии распределены нормально.


Далее при t-тесте следуют действия, обычные при тестировании гипотез:

- Считаем t-статистику.
- Считаем вероятность получить такое значение статистики при условии, что нулевая гипотеза верна (p-value).
- Сравниваем эту вероятность (p-value) с заданным уровнем значимости ($\alpha$). Если эта вероятность меньше заданного уровня значимости --- отвергаем нулевую гипотезу.

__Осторожнее с выводами! Значение p ничего не говорит о том, верна ли на самом деле нулевая гипотеза.__


## Экспрессия белков у гребешков _Pecten maximus_

Как работае t-тест мы будем разбирать на примере более полных данных об экспрессии белков у гребешков из работы @artigaud2015proteomic.

### Задание 1

- Откройте данные из файлов `Prot_Br_H_T.csv` и `Prot_Br_H_T_factor.csv` и сохраните их в переменных `expr` и `fact`.
- Трансформируйте и нормализуйте значения экспрессии.
- Посмотрите, какая информация известна о пробах.

```{r hide_button=TRUE, purl=FALSE}
library(limma)
# Открываем данные экспрессии
expr <- read.table("data/Prot_Br_H_T.csv", header = TRUE, sep = ";", row.names = 1)
fact <- read.table("data/Prot_Br_H_T_factor.csv", header = TRUE, sep = ";", row.names = 1)

# Хорошо бы проверить, соответствует ли число проб в обоих файлах
dim(expr)
dim(fact)

# Есть ли пропущенные значения?
colSums(is.na(expr))
# Есть ли нули (они будут мешать при логарифмировании)
colSums(expr == 0)

# нормализуем и логарифмируем
expr_norm <- normalizeQuantiles(log2(expr + 1))

# Что известно о пробах?
str(fact)
table(fact$Oxygen, fact$Temperature)
```

### Задание 2

Отберите только данные экспрессии и метаданные, относящиеся к гребешкам из 10 и 25 градусов, которые жили при нормальном количестве кислорода. Назовите получившиеся переменные `expr_subset` и `fact_subset`.

```{r, hide_button=TRUE, purl=FALSE}
f_subset <- fact$Oxygen == "Normox" & fact$Temperature %in% c("10C", "25C")
expr_subset <- expr_norm[, f_subset]
fact_subset <- droplevels(fact[f_subset, ])
```

## t-тест в R

Давайте сравним уровень экспрессии одного из белков (например, шестого) между группами при помощи простого t-критерия.

```{r}
groups <- fact_subset$Temperature == "10C"
t.test(x = expr_subset[6, groups], y = expr_subset[6, !groups])
```

Но у нас всего `r nrow(expr_subset)` белков. Было бы не удобно делать все эти сравнения вручную. Поэтому, давайте научимся добывать из объекта, возвращаемого `t.test()` значение p-value.

```{r}
t_result <- t.test(x = expr_subset[6, groups], y = expr_subset[6, !groups])
str(t_result)
t_result$p.value
```

Теперь мы готовы посчитать t-тест для каждого белка. Для этого нам понадобится:

1. написать функцию, которая считает t-test и добывает p-value
2. к каждой строке данных применить наш t.test

```{r}
# 1) пишем функцию, которая считает t-test и добывает p-value
t_p_val <- function(x, f1, f2) {
  tryCatch(t.test(x = x[f1], y = x[f2])$p.value,
           error = function(e) NA)
}
# тестируем функцию
t_p_val(expr_subset[6, ], f1 = groups, f2 = !groups)

# 2) к каждой строке данных применяем наш t.test
pvals <- apply(X = expr_subset, MARGIN = 1, FUN = t_p_val, 
               f1 = groups, f2 = !groups)

```

Все готово, мы посчитали p-values для всех белков. 

```{r}
# В результате мы получаем вектор p-values
head(pvals)
class(pvals)
```

### Задание 3

- Сколько белков, значимо меняющих экспрессию, мы нашли?
- Экспрессия каких белков различается?

```{r, hide_button=TRUE, purl=FALSE}
# Сколько белков, значимо меняющих экспрессию, мы нашли?
sum(pvals <= 0.05, na.rm = TRUE)
# Экспрессия каких белков различается?
ids_dif <- which(pvals <= 0.05)
rownames(expr_subset)[ids_dif]
```

__Но это пока еще не правильные p-values!__

# Проблема множественных тестов

В результате протеомного исследования обычно получают данные об экспрессии сотен--тысяч белков. При анализе дифференциальной экспрессии для каждого белка нам нужно протестировать нулевую гипотезу $H_0: \bar{A} = \bar{B}$. 

В случае, если у нас всего один белок --- мы делаем всего один статистический тест. В этом единственном тесте мы заранее фиксируем вероятность совершить ошибку I рода на уровне значимости $\alpha = 0.05$ (или $\alpha = 0.01$). 

Но представьте себе, что мы сравниваем уровень экспрессии 1000 белков. Даже если на самом деле их экспрессия не различается в двух группах ($H_0$ на самом деле справедлива), мы получим по крайней мере в 50 из этих тестов $p < 0.05$. Т.е. в 50 из 1000 тестов мы совершим ошибку I рода --- найдем различия экспрессии там, где их нет. Это непозволительно большое количество ошибок.

Если вероятность ошибки I рода $\alpha = 0.05$, тогда 

Вероятность не совершить ошибку первого рода $1 - \alpha$. 

Вероятность не совершить ошибку первого рода ни в одном из сравнений $(1 - \alpha)^{m}$

Вероятность совершить хотябы одну ошибку первого рода в группе сравнений $1 - (1 - \alpha)^{m}$

|Если не делать поправок на число сравнений...         | 1 сравнение | семейство из 1000 сравнений |
|:--------:|:-----------:|:---------------------------:|
| Число ошибок I рода на число сравнений<br />Per comparison error rate | 0.05 | 0.05 |
| Ожидаемое число ошибок <br /> Per family error rate | 0.05 | 0.05 * 1000 = 50 |
| Вероятность получить хотябы одну ошибку I рода <br /> Family-wise error rate (FWER) | 0.05 | $$1 - (1 - 0.05)^{1000} = 1$$ |

## Контроль вероятности совершить хоть одну ошибку I рода (Family-wise error rate, FWER)

__Вероятность получить хотябы одну ошибку I рода в группе сравнений (Family-wise error rate, FWER)__ можно зафиксировать на каком-нибудь приемлемом уровне. Примеры таких процедур --- поправка Бонферрони и метод Хольма-Бонферрони.

__Поправка Бонферрони__ --- процедура в один шаг. Отклоняем все нулевые гипотезы, для которых $p \le \frac {\alpha} {m}$. Например, если вам нужно сделать 1000 сравнений, чтобы вероятность совершить ошибку I рода была 0.05, то нужно использовать $p = 0.05/1000 = 0.00005$ для каждого сравнения. Это очень жесткая поправка. Мощность такого теста будет очень мала.

__Метод Хольма-Бонферрони__ --- пошаговая процедура. 

Чтобы зафиксировать $FWER \le \alpha$:

- Сортируем {p_n} p-values, полученные в тестах, в порядке возрастания

$p_{1} \le p_{2} \le \cdots \le p_{n - 1} \le p_{n}$

- Вводим поправку для уровня значимости

$\hat{p_{j}} = min{\{(n - j + 1) \cdot p_{j}, 1\}}$

В таблице приведены результаты нескольких сравнений. Для каждой из доверительных вероятностей (p-values) мы получили свой порог значимости при помощи поправки Хольма-Бонферрони: 


```{r echo=FALSE, purl=FALSE, results='asis'}
n <- 5
alph <- 0.05
dat <- data.frame(
  rank = 5:1, 
  p_val = c(0.015, 0.01, 0.035, 0.04, 0.046))

dat$adj <- n - dat$rank + 1
dat$p_adj <- dat$adj * dat$p_val
dat$h0 <- ifelse(dat$p_adj <= alph, "Да", "Нет")

colnames(dat) <- c("Ранг ($j$)", "$\\mathbf{p_{j}}$", "$(n - j + 1)$",  "$\\mathbf{\\hat{p_{j}}}$", "Отвергаем $H_0$?")

library(knitr)
kable(dat, format = "markdown")
```

Недостаток применения контроля FWER --- снижение мощности всех тестов: мы каким либо способом снижаем $\alpha$ для каждого сравнения, в результате возрастает $\beta$, а значит снижается мощность $1 - \beta$.

Процедуры контроля FWER неоправданно жесткие. Они контролируют вероятность возникновения __хотябы одной__ ошибки первого рода в группе сравнений. Эти процедуры устроены так, как будто мы проверяем обобщенную нулевую гипотезу --- об отсутствии различий во всех сравнениях. На самом деле, эта гипотеза редко интересна с практической точки зрения.  Считается, что небольшое число ошибок I рода все же можно допустить (например, при анализе геномных или протеомных данных). Именно поэтому часто указывают не уровни значимости после коррекции на множественные сравнения (p-values), а частоту ложноположительных результатов (частоту возникновения ошибок I рода).

## Контроль частоты ложноположительных результатов (false discovery rate, FDR)

__Частота ложноположительных результатов (false discovery rate, FDR)__ --- это доля ошибок I рода относительно общего числа отвегнутых $H_0$. Для контроля FDR используется, например, процедура Беньямини-Хохберга.

Алгоритм процедуры Беньямини-Хохберга

Чтобы зафиксировать $FDR \le \gamma$:

- Сортируем {p_n} p-values, полученные в тестах, в порядке возрастания

$p_{1} \le p_{2} \le \cdots \le p_{n - 1} \le p_{n}$

- Находим такое значение p-value с наибольшим рангом $j$, чтобы 

$p_{j} \le \frac{j}{n}\times \gamma$

- Различия во всех тестах с рангами меньше $j$ считаем значимыми

Для каждого теста можно вычислить точную ожидаемую долю ложноположительных результатов. $\mathbf{q-value}$ --- минимальное значение FDR при котором результат конкретного теста можно считать значимым (Storey 2002, Storey Tibshirani 2003).

Например, для 15 сравнений результаты процедуры Беньямини-Хохберга могут выглядеть так:

```{r echo=FALSE, purl=FALSE, results='asis'}
sim_pval <- c(0.000114, 0.000268, 0.005265, 0.005674, 0.006273, 0.008295, 
0.009347, 0.019499, 0.033163, 0.048919, 0.049971, 0.055996, 0.062212, 
0.079793, 0.080519)
n <- length(sim_pval)
dat <- data.frame(rank = rank(sim_pval), pval = round(sim_pval, 4))

gamma <- 0.05

dat$adj <- gamma * dat$rank / n
dat$h0 <- ifelse(dat$pval <= dat$adj, "Да", "Нет")
library(qvalue)
dat$q <- round(qvalue(dat$pval, fdr.level = 0.05, pi0 = 1)$qvalues, 4)

colnames(dat) <- c("Ранг ($j$)", "$\\mathbf{p_{j}}$", "$\\mathbf{\\frac{j}{n}\\times \\gamma}$", "Отвергаем $H_0$?", "q-value")

library(knitr)
kable(dat, format = "markdown")
```

## Контроль FWER и FDR в R

Поправки к p-values в R можно сделать при помощи функции `p.adjust()`. Аргумент `method` функции `p.adjust()` задает тип поправки.

```{r}
p_bonf <- p.adjust(pvals, method = "bonferroni")
# было
head(pvals)
# стало
head(p_bonf)
```

У скольких белков экспрессия значимо различается после поправки Бонферрони?

```{r}
sum(p_bonf <= 0.05, na.rm = TRUE)
```

Названия белков, экспрессия которых значимо различается после поправки Бонферрони?

```{r}
names(pvals)[p_bonf <= 0.05]
```

### Задание 4

- Cколько значимо различающихся белков будет найдено после поправки Хольма?
- Cколько --- после применения процедуры Беньямини-Хохберга?

```{r, hide_button=TRUE, purl=FALSE}
# С поправкой Хольма
p_holm <- p.adjust(pvals, method = "holm")
sum(p_holm <= 0.05, na.rm = TRUE)

# После процедуры Беньямини-Хохберга (FDR)
p_bh <- p.adjust(pvals, method = "BH")
sum(p_bh <= 0.05, na.rm = TRUE)
```


# Проблемы с обычным t-тестом

## 1.t-статистика может не следовать t-распределению

t-статистика, вычисленная на реальных данных может быть не t-распределена, из-за этого можно прийти к неправильным выводам.

Возможные решения:

- использование непараметрических тестов, которые не делают никаких предположений о форме распределения. Недостаток --- малая мощность.
- использование бутстреп-оценок. Недостаток --- нужен большой объем выборок.

## 2.Дисперсия экспрессии оценивается неточно на малых выборках

При рассчете обычного t-критерия для оценки дисперсии экспрессии белков используется выборочная оценка дисперсии. Если повторностей мало, то оценки дисперсии получаются нестабильными и не точными. t-критерий лучше работает при __большом__ числе повторностей, т.к. тогда при помощи $s^2$ удается точнее оценить $\sigma^2$.

Есть другие способы оценить дисперсию --- можно использовать информацию о других белках, чтобы оценить распределение возможных значений дисперсии (модерируемый t-критерий, см. ниже).

## 3.Разная дисперсия экспрессии

У разных белков может быть очень разная дисперсия экспрессии.

<!-- График: несколько белков, по оси х группы, по оси н уровень экспрессии. То же самое можно в виде боксплота, если много значений (больше 5). Каким различиям средних мы будем больше верить --- там где большая или маленькая дисперсия? -->

<!-- ```{r variability} -->

<!-- ``` -->

Часто оказывается, что большая разница уровней экспрессии наблюдается у белков с низким уровнем экспрессии.

<!-- RI-plot - график, где по одной оси (I) --- интенсивность экспрессии, а по другой оси (R) --- логарифм соотношения уровней экспрессии.  -->

<!-- ```{r riplot} -->

<!-- ``` -->

Из-за этой особенности данных простое применение t-критерия может привести к некорректным выводам:

- Даже ничтожные различия уровня экспрессии могут оказаться достоверными для белков с небольшой дисперсией экспрессии (т.к. небольшие стандартные ошибки). 
- Даже очень сильные различия уровня экспрессии могут оказаться недостоверными для белков с большой дисперсией экспрессии (т.к. стандартные ошибки велики).

<!-- volcano plot: по оси х разница средних логарифмов экспрессии, по оси y - $-log_{10}p-value$. Граница уровня значимости на лог шкале $-log_{10}0.01 = 2$, все что выше - значимо, все что ниже - нет. Сверху, справа и слева - белки, которы значимо меняют экспрессию в ту и др. сторону больше чем в заданное число раз. Внизу справа и слева - белки, которые сильно но незначимо меняют экспрессию. -->

<!-- ```{r volcano} -->

<!-- ``` -->


<!-- ## Модифицированный t-критерий -->

<!-- Модифицированный t-критерий (Witten, Tibshirani, 2007)  -->

<!-- $t_{mod} = \frac {\bar {A} - \bar {B}}{s + s_o}$, -->

<!-- где $s_o$ - это константа, кот. минимизирует коэф. вариации $t_{mod}$. -->

<!-- $s_o$ выбирается при помощи Significance Analysis of Microarrays (SAM) (Tusher et al., 2001) -->

<!-- Модифицированный t-критерий выбирает гены, у которых одновременно большая разница экспрессии и небольшие SE.  -->

# Moderated t-test (The Good)

<img src="images/the_good1.jpg" width=300px>

Реализован в пакете `limma` `r citep(citation("limma"))`

"Поправленные" стандартные отклонения (shrunk standard deviations)

$$\tilde{s}^{2}_{i} = \frac {s^{2}_{i} d_{i} + s^{2}_{0} d_{0}} {d_{i} + d_{0}}$$

Модерированный t-критерий

$$\tilde{t}_{g} = \frac {\bar{M}_{g}} {\tilde{s}_{g}\sqrt{c_{g}}}$$

После его применения не будет случаев, когда t-статистика велика просто потому, что стандартная ошибка оказалась маленькой.

Линейные модели (дисперсионный и регрессионный анализ) можно использовать для тестирования сложных гипотез. Модерированный t-критерий, как и обычный, можно использовать для оценки значимости коэффициентов линейных моделей. Мы найдем дифференциально-экспрессируемые белки при помощи линейной модели.

Уравнение линейной регрессии, которое мы будем использовать

$$\hat y _{i} = b _0 + b _1 x _{1i} + \epsilon _{i}$$

В нем $\hat y _{i}$ --- зависимая переменная, уровень экспрессии, $b _0$ и $b _1$ - коэффициенты, $x _{1i}$ --- независимая переменная (предиктор, фактор), описывающая принадлежность гребешка к группе, $\epsilon _{i}$ --- остатки от линейной регрессии, $i = 1, 2, \cdots, n$ --- значения.

Поскольку мы сравниваем всего два состояния фактора, их можно закодировать при помощи одного единственного предиктора $x _{1i}$. Этот предиктор будет принимать значение 0 на базовом уровне фактора, и значение 1 на другом уровне. В таком случае, коэффициент $b_0$ будет означать уровень экспрессии на базовом уровне фактора, а коэффициент $b_1$ --- разницу уровней экспрессии между двумя уровнями фактора.

Уравнение линейной регрессии можно переписать в виде матриц:

$$\left[\begin{array}{c}
\hat y_1 \\ \hat y_2 \\ \vdots \\ \hat y_n 
\end{array}\right] = 
\left[\begin{array}{cc}
1 & x_{1,1} \\
1 & x_{2,1} \\
\vdots & \vdots \\
1 & x_{n,1} 
\end{array}\right] \cdot
\left[\begin{array}{c}
b _0 \\ b _1
\end{array}\right] +
\left[\begin{array}{c}
\epsilon _1 \\ \epsilon _2 \\ \vdots \\ \epsilon _n
\end{array}\right]
$$

Сокращенная форма записи линейной регрессии в матричном виде выглядит так: $\mathbf{\hat y} = \mathbf{X} \mathbf{b} + \mathbf{\epsilon}$.

Чтобы подобрать в R линейную модель экспрессии при помощи пакета `limma`, нужно будет создать модельную матрицу $\mathbf{X}$. Затем при помощи функции `lmFit()` мы подберем коэффициенты линейной регрессии. Поскольку в этом примере мы сравниваем всего два уровня фактора, чтобы проверить, различается ли экспрессия какого-либо белка между ними, нужно будет всего лишь проверить значимость второго коэффициента линейной модели $b _1$. Это мы сделаем как раз при помощи модерированного t-критерия. Кроме того, нам придется сделать поправку на множественные сравнения, поскольку мы по-прежнему тестируем много белков сразу. Наконец, мы выберем дифференциально-экспрессируемые белки и построим тепловую карту их экспрессии.

__Внимание! В `limma` сложно учесть технические реплики. Их проще усреднить перед анализом.__

## Moderated t-test в R

В принципе, пакет limma позволяет анализировать данные экспрессии в виде обычных датафреймов, но есть некоторые выгоды при использовании специального формата ExpressionSet.

Загружаем данные, создаем ExpressionSet

```{r}
library(Biobase)

# Данные экспрессии
expr_data <- as.matrix(expr_subset)

# Данные о пробах
pheno_data <- fact_subset
pheno_metadata <- data.frame(
  labelDescription = c("Oxygen concentration", "Temperature"), 
  row.names=c("Oxygen", "Temperature"))
pheno_data <- new("AnnotatedDataFrame", 
                 data = pheno_data, 
                 varMetadata = pheno_metadata)

# Данные о признаках (белках)
feature_data <- data.frame(Spot = rownames(expr_data))
rownames(feature_data) <- rownames(expr_data)
feature_metadata <- data.frame(
  labelDescription = c("Spot number"),
  row.names = c("Spot"))
f_data <- new("AnnotatedDataFrame", 
              data = feature_data, 
              varMetadata = feature_metadata)

# Данные об эксперименте
experiment_data <-
  new("MIAME",
      name = "Sebastien Artigaud et al.",
      lab = "lab",
      contact = "email@domain.com",
      title = "Proteomic responses to hypoxia at different temperatures in the great scallop (Pecten maximus).",
      abstract = "Abstract",
      other = list(notes = "partial dataset from Artigaud et al. 2015"))

# Собираем вместе
exp_set <-
  ExpressionSet(assayData = expr_data,
                phenoData = pheno_data,
                featureData = f_data,
                experimentData = experiment_data)
```

Мы хотим сравнить уровень экспрессии каждого белка в группах, закодированных фактором `Temperature`. В наших данных две такие группы по 5 проб.

```{r}
table(pData(exp_set)$Temperature)
```

Чтобы подобрать линейную модель в `limma` нам понадобится модельная матрица.

```{r}
# Модельная матрица
X <- model.matrix(~ Temperature, pData(exp_set))
X
```

Подбираем линейную модель для _i_-того белка
```{r}
# линейная модель
fit <- lmFit(exp_set, design = X, method = "robust", maxit = 1000)
names(fit)
```

Теперь самое важное --- Empirical Bayes statistics.

```{r}
# Empirical Bayes statistics
efit <- eBayes(fit)
names(efit)
```

Результат --- таблица дифференциально-экспрессируемых белков

```{r}
# Таблица дифференциально-экспрессируемых белков
topTable(efit, coef = 2)
numGenes <- nrow(exprs(exp_set))
full_list <- topTable(efit, number = numGenes)
# View(full_list)
```

## MA-plot

Давайте создадим функцию, которая будет рисовать MA-plot, используя объект, возвращенный `eBayes()`.

Аргументы:

- `efit` - объект результатов `eBayes()`
- `coef` - порядковый номер коэффициента линейной модели, для которого нужно сделать тест
- `n` - число белков, которые нужно подписать
- `sigif` - выделять ли дифференциальные белки?
- `fdr` - уровень FDR коррекции
- `lfc` - log fold change
- `text` - подписывать ли n белков с сильнее всего различающейся экспрессией  
и т.д.

```{r}
MA_limma <- function(efit, coef, n = 10, signif = TRUE, fdr = 0.05, lfc = 0, text = TRUE, cex.text = 0.8, col.text = "grey20", main = "MA-plot", xlab = "Average log-expression", ylab = "Expression log-ratio", pch = 19, pch.signif = 21, col = "darkgreen", alpha = 0.3, cex = 0.3, ...){
  # соотношение и интенсивность
  R <- efit$coefficients[, coef]
  I <- efit$Amean
  # прозрачный цвет
  col_btransp <- adjustcolor(col, alpha.f = alpha)
  # график
  plot(I, R, cex = cex, main = main, pch = pch, xlab = xlab, ylab = ylab, col = col_btransp, ...)
  abline(h = 0)
  # отмечаем дифференциально-экспрессируемые белки
  if(signif){
    sign <- p.adjust(efit$p.value[, coef], method = "BH") <= fdr
    large <- abs(efit$coefficients[, coef]) >= lfc
    points(I[sign & large], R[sign & large], cex = cex*2, col = "orange2", pch = pch.signif)
  }
  # подписываем первые n белков с сильнее всего различающейся экспрессией
  if(text){
    ord <- order(efit$lods[, coef], decreasing = TRUE)
    top_n <- ord[1:n]
    text(I[top_n], R[top_n], labels = efit$genes[top_n, ], pos = 4, cex = cex.text, col = col.text)
  }
}
```


```{r}
MA_limma(efit, coef = 2, n = 3)
```

### Задание 5

Сравните графики:

- MA-plot первых 20 дифференциально экспрессируемых белков
- MA-plot первых 20 дифференциально экспрессируемых белков, но таких, чтобы уровень экспрессии различался в 2 раза
- MA-plot первых 20 дифференциально экспрессируемых белков с уровнем экспрессии различающимся в 5 раз


```{r, hide_button=TRUE, purl=FALSE}
MA_limma(efit, coef = 2, n = 20, text = F)
MA_limma(efit, coef = 2, n = 20, text = F, lfc = 1)
MA_limma(efit, coef = 2, n = 20, text = F, lfc = log2(5))
```

## Сохраняем список всех белков в файл

```{r}
dir.create("results")
write.table(full_list, file = "results/pecten_diff_expression.csv", sep = "\t", quote = FALSE, col.names = NA)
```

## Добываем дифференциально-экспрессируемые белки для дальнейшей работы

```{r}
# Первые 20 дифференциальных белков
my_list <- topTable(efit, coef = 2, n = 20)
# Фильтруем ExpressionSet
dif_exp_set <- exp_set[fData(exp_set)$Spot %in% my_list$Spot, ]
```

## Тепловая карта экспрессии дифференциальных белков

### Задание 6

Нарисуйте две тепловые карты диффенциально-экспрессируемых белков:

- по сырым данным,
- после дополнительной стандартизации по белкам.

Рассмотрите, чем отличаются эти карты. Какая из них лучше подходит для представления результатов анализа дифференциальной экспрессии?

```{r fig.height=8, hide_button=TRUE, purl=FALSE}
library(gplots)
dat <- as.matrix(exprs(dif_exp_set))

# Короткие имена гребешков для графиков
part1 <- substr(x = pData(dif_exp_set)$Oxygen, start = 0, stop = 1)
part2 <- substr(x = pData(dif_exp_set)$Temperature, start = 0, stop = 2)
colnames(dat) <- make.unique(paste(part1, part2, sep = "_"))

pal_green <- colorpanel(75, low = "black", mid = "darkgreen", high = "yellow")
heatmap.2(dat, col = pal_green, scale = "none", key=TRUE, symkey = FALSE, density.info = "none", trace = "none", cexRow = 0.9, cexCol = 1, margins = c(4, 3), keysize = 0.8, key.par = list(mar = c(3, 0.1, 3, 0.1)))

pal_blue_red <- colorpanel(75, low = "steelblue", mid = "black", high = "red")
heatmap.2(dat, col = pal_blue_red, scale = "row", key = TRUE, symkey = FALSE, density.info = "none", trace = "none", cexRow = 0.9, cexCol = 1, margins = c(4, 3), keysize = 0.8, key.par = list(mar = c(3, 0.1, 3, 0.1)))
```

<!-- ## `topTreat()` -->

<!-- ```{r} -->
<!-- tfit <- treat(fit, lfc = 1) -->
<!-- topTreat(tfit, coef = 2, number = 20) -->
<!-- ``` -->

<!-- ## Bootstrap -->

<!-- - Нет особенных предположений о форме распределения -->
<!-- - Алгоритм: Считаем t-статистику. Много раз случайным образом переставляем данные между группами и снова считаем t-статистику, чтобы получить ее распределение после случайных перестановок. Считаем уровень значимости t-статистики, как долю пермутаций в которых получилось значение t-статистики больше данного. -->
<!-- - Нужно разумное число повторностей (минимум 4-6), чтобы было что переставлять -->

<!-- ## Дисперсионный анализ (Analysis Of Variance, ANOVA) -->

<!-- - Можно контролировать много факторов сразу -->
<!-- - Нужно неск. повторностей <!-- (я бы сказала, что не меньше 4) -->
<!-- - Должны выполняться условия применимости ANOVA -->
<!-- - Если сравниваемых групп больше двух, то нельзя точно сказать, между  какими группами достоверные различия. После ANOVA нужны пост хок тесты или заранее запланированные сравнения при помощи линейных контрастов.  -->

<!-- ## Адаптивный порог для Fold change -->

<!-- Если при пороге отсечения 2 или 1.5 оказывается выбрано слишком большое число белков, можно применять "адаптивный порог" (Fukuoka et al., 2011). Спорный метод - субъективное число групп с разным пороговым уровнем экспрессии.  -->

<!-- Алгоритм: Нужны две технические повторности, чтобы оценить распределение шума. Нормализуем данные. Логарифмируем. Считаем соотношение экспрессий между техническими повторностями. Делим на $i$-групп по значениям нормализованной экспрессии с численностью $N_i$. (Исключаем группы где оказалось меньше 100 генов/белков - писали для конференции когда-то). Для каждой группы выбрать случайным образом половину генов в группе и найти для них минимальную и максимальную FC (повторить $N_i/2$ раз). Рассчитать доверительный интервал среднего максимального и минимального FC. CIupper * constant - это верхняя граница значимости для группы, а CIlower / constant - это нижняя граница значимости для группы. Если увеличивать constant, то должен снижаться уровень ложноположительных срабатываний. Повторить для других групп. Найденные пороги используются для сравнения тритментов. -->

<!-- Аналогичные методы с разными порогами отсечения: (Tsien et al., 2002b,  Draghici, 2002) -->

<!-- ### Эмпирическая баесовская статистика. -->

<!-- ***** -->

<!-- Применение: смотрим на "типичные" значения стандартных ошибок. Поскольку данные фиксированные и белков много, можно оценить как выглядят "типичные" стандартные ошибки у похожих белков. -->




## Ссылки

```{r include=FALSE}
write.bibtex(file="bibs/04_packages.bib")
```
