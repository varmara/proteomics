---
title: "Предварительная обработка данных"
author: "Марина Варфоломеева"
output:
  html_document:
    toc: yes
bibliography:
  - "bibs/references.bib"
  - "bibs/02_packages.bib"
csl: "bibs/ecology.csl"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library("knitcitations")
cleanbib()
options("citation_format" = "pandoc")
```

---

В этом разделе мы поговорим о том, как готовить данные 2-DIGE для статистической обработки в R `r citep(citation())`.

- [Код к этому занятию](https://raw.githubusercontent.com/varmara/proteomics-course/gh-pages/02_data_preprocessing.R)
- Данные:
    - [Prot_Br_H_T.csv](https://raw.githubusercontent.com/varmara/proteomics-course/gh-pages/data/Prot_Br_H_T.csv) [@artigaud_proteomic_2015]
    - [Prot_Br_H_T_factor.csv](https://raw.githubusercontent.com/varmara/proteomics-course/gh-pages/data/Prot_Br_H_T_factor.csv) [@artigaud_proteomic_2015]
- Пакеты (инсталлируйте при необходимости)

```{r eval=FALSE}
# Из репозитория CRAN
install.packages(c("Hmisc", "RColorBrewer"))
# С сайта Bioconductor
source("https://bioconductor.org/biocLite.R")
biocLite(c("Biobase", "prot2D", "impute", "pcaMethods", "limma", "hexbin"))
```

---

# Пример: протеом жабр гребешка _Pecten maximus_

Для работы мы будем использовать данные о протеоме жабр гребешка _Pecten maximus_ `r citep(citation("prot2D"))`. Гребешков подвергали воздействию двух разных температур (15 и 25 градусов, по 6 гребешков в каждой группе). В этом исследовании, в общей сложности, было обнаружено 766 пятен.

Загрузим данные из пакета `prot2D` `r citep(citation("prot2D"))`, и сразу посмотрим, к какому классу они принадлежат

```{r, message=FALSE, warning=FALSE}
library(prot2D)
data(pecten)
data(pecten.fac)
class(pecten)
class(pecten.fac)
```

В датафрейме `pecten` хранятся необработанные данные интенсивностей пятен (_raw volume data_), а в датафрейме `pecten.fac` описана принадлежность гребешков к разным вариантам экспериментальной обработки. В данном случае, всего один фактор --- `Condition`.

```{r}
dim(pecten)
dim(pecten.fac)
head(pecten, 2)
head(pecten.fac)
```

# Импутация пропущенных значений.

Довольно часто бывает так, что в матрице экспрессии могут пустовать некоторые ячейки. Пятно может быть обнаружено на одном геле, но отсутствовать на других в силу различных причин. Например, в силу различий между биологическими репликами, из-за различий между техническими репликами по техническим причинам, из-за ошибок в идентификации пятен, из-за плохой изоэлектрической фокусировки, из-за малого количества белка и т.п.

Отсутствие пятна на геле может обозначать разные вещи: пептид может действительно отсутствовать, либо он отсутствует в силу технических причин, либо он все же присутствует в концентрации ниже порога определения. Отсутствие пятна на всех технических повторностях может скорее означать отсутствие пептида, в таких ячейках можно записать нули. Однако, если пропущенные значения появились в результате неправильного сопоставления пятен, то замена их нулями может исказить данные. Если мы имеем дело с истинно пропущенными значениями, то такие ячейки мы оставим пустыми, а R во время чтения данных автоматически преобразует их в `NA`.

Для импутации используют данные по всем техническим и биологическим репликам. После импутации можно будет усреднить технические реплики, либо анализировать их отдельно.


В нашем примере пропущенных значений нет. В этом легко убедиться при помощи комбинации из нескольких функций. 

```{r}
colSums(is.na(pecten))
```

Функция `is.na()` --- проверяет, равно ли значение ее аргумента `NA` и возвращает логическое значение. `is.na(pecten)` вернет двумерную таблицу, в которой `TRUE` будет встречаться, только если соответствующий элемент в датафрейме `pecten` был `NA`. Логическим значениям `TRUE` и `FALSE` соответствуют 1 и 0. Если мы посчитаем суммы значений в каждом из столбцов таблицы при помощи функции `colSums()`, то мы получим число `NA` для каждого из них.

Чтобы можно было сейчас потренироваться заполнять пропущенные значения, нам потребуется, чтобы в датасете `pecten` всетаки они были, поэтому мы специально заменим случайно выбранные ячейки на `NA`.

```{r}
# Функция, которая заполняет NA заданную пропорцию (frac) случайно расположенных ячеек в датафрейме (dfr) 
spoil <- function(dfr, frac = 0.1, seed){
  # считаем число строк, столбцов
  rows <- nrow(dfr)
  cols <- ncol(dfr)
  # сколько значений нужно заменить на NA
  n_nas <- ceiling(frac * rows * cols)
  set.seed(seed)
  row_id <- sample(1:rows, size = n_nas, replace = TRUE)
  col_id <- sample(1:cols, size = n_nas, replace = TRUE)
  # заменяем на NA
  sapply(seq(n_nas), function(x){dfr[row_id[x], col_id[x]] <<- NA})
  return(dfr)
}
# "Портим" данные пропущенными значениями.
spect <- spoil(dfr = pecten, frac = 0.2, seed = 3194)
```

Теперь можно приступать к тренировке заполнения пропущенных значений.

Ниже приведены некоторые распространенные способы заполнения пропущенных значений. Не все из них одинаково хороши, кроме того, есть и много других, помимо этого списка [см., например, @sellers_statistical_2012].

## Исключение переменных, в которых есть `NA`

Исключение переменных, в которых есть `NA` (использование только "надежных" пептидов) сильно снижает "интересность" анализа, потому что многие пептиды будут исключены, останется меньше пятен.

```{r}
f_na <- rowSums(is.na(spect)) < 1
ipect_none <- spect[f_na, ] 
```

Если сравнить размеры получившихся датафреймов, видно, что пришлось исключить очень много пептидов.

```{r}
dim(spect)
dim(ipect_none)
```

## Замена `NA` средними значениями

Замена `NA` средними значениями экспрессии данного пептида в разных образцах (mean substitution). Это довольно грубый вариант, который вносит искажения в данные.


```{r, message=FALSE, warning=FALSE}
library(Hmisc) # для функции impute
ipect_mean <- t(apply(X = spect, MARGIN = 1, FUN = impute, fun = mean))
```


## Замена `NA` средним по _k_-ближайшим соседям

Очень хорший метод импутации - замена `NA` при помощи среднего по _k_-ближайшим соседям [_k-nearest neighbour averaging_; @troyanskaya_missing_2001]. По качеству импутации с этим методом может соперничать только баесовский метод. Метод _k_-ближайших соседей реализован в пакете `impute` на Bioconductor `r citep(citation("impute"))`.

![Импутация по k-ближайшим соседям](images/SimilarPeptides.png)

Метод импутации по k-ближайшим соседям заменяет каждое пропущенное значение взвешенным средним, рассчитанным по _k_-ближайшим пептидам-соседям, у которых это значение не пропущено [@troyanskaya_missing_2001]

Допустим, у пептида _#1_ есть пропущенное значение экспрессии в пробе _A_. Алгоритм вначале находит _k_ пептидов с похожим паттерном экспрессии (соседей). Соседство определяется при помощи евклидова расстояния между пептидами, рассчитанного по пробам с известной экспрессией. (Подробнее о различных способах рассчета расстояний можно будет узнать в разделе о классификации данных). Далее, рассчитывается взвешенное среднее экспрессии в пробе _А_ в этих _k_ похожих пептидах. Вклад каждого пептида взвешивают по степени его сходства с пептидом _#1_.

Может случиться так, что у некоторых похожих пептидов есть пропущенные значения экспрессии на некоторых других гелях. В этом случае, сходство между пептидами определяется как среднее сходств, рассчитанных по гелям без пропущенных для этих пептидов данных. Наконец, если вдруг так оказалость, что у нескольких похожих пептидов неизвестна экспрессия в одном и том же геле, тогда пропущенные значения алгоритм заменяет средней экспрессией по гелю.

Для импутации при помощи среднего по _k_-ближайшим соседям матрицу интенсивностей сначала нужно транспонировать, чтобы пробы были в строках, а пептиды в столбцах. 

```{r, message=FALSE, warning=FALSE}
library(impute)
# транспонируем, чтобы пептиды были в столбцах
trans_spect <- t(spect) 
knn_dat <- impute.knn(trans_spect, k = 5)
# в результате импудации получился сложный объект - список
str(knn_dat)
# нам понадобится из него взять элемент data
ipect_knn <- t(knn_dat$data)
```


## Импутация пропущенных значений при помощи байесовского анализа главных компонент

Замена `NA` при помощи байесовского анализа главных компонент [_Bayesian principal component analysis_, BPCA; @bishop_bayesian_1999]. Сравнение результатов импутации пропущенных значений при помощи различных методов показало, что этот метод --- явный фаворит по качеству результата [@pedreschi_treatment_2008]. Байесовский анализ главных компонент реализован в пакете `pcaMethods` на Bioconductor `r citep(citation("pcaMethods"))`. Здесь мы только бегло перечислим основные особенности метода, а в последнем разделе курса рассмотрим подробнее, как работает обычный анализ главных компонент.

Байесовский анализ главных компонент был адаптирован для заполнения пропущенных значений [@oba_bayesian_2003]. Он состоит из двух частей: из анализа главных компонент (на основе максимизации ожидания) и байесовской модели. BPCA представляет многомерный массив векторов экспрессии в виде линейной комбинации меньшего числа главных осей и ошибки (ошибки и факторные координаты нормально распределены). Оптимальное для представления данных число главных осей находят при помощи кросс-валидации (метод называется `kEstimate`). Главные оси, найденные при помощи BPCA, чаще всего не будут ортогональны, в отличие от обычного PCA. Поскольку в исходной матрице есть пропущенные значения, главные оси будут состоять из известной и неизвестной частей. На заключительном этапе при помощи байесовского оценивания находят одновременно пропущенные значения, неизвестную часть главных осей и параметры нормального распределения.

В реализации BPCA из пакета `pcaMethods` пробы служат наблюдениями, гены --- переменными, т.е. для применения BPCA нужно транспонировать матрицу экспрессии `r citep(citation("pcaMethods"))`. Кроме того, нужно предварительно центрировать (вычесть среднее) и стандартизовать (разделить на стандартное отклонение) значения экспрессии в каждом столбце.

```{r, message=FALSE, warning=FALSE}
library(pcaMethods)
# транспонируем
trans_spect <- t(spect) 
# центрируем и стандартизуем каждый столбец при помощи функции prep() из пакета pcaMethods.
scaled_spect <- prep(trans_spect, scale = "uv", center = TRUE, simple = FALSE)
# bpca
pc <- pca(scaled_spect$data, method="bpca", nPcs=2)
# восстановленные полные данные (центрированные и стандартизованные)
complete_obs <- completeObs(pc)
# возвращаем восстановленные данные в исходный масштаб
scaled_spect_complete <- prep(complete_obs, scale = scaled_spect$scale, center = scaled_spect$center, reverse = TRUE)
dim(scaled_spect_complete)
# транспонируем обратно
ipect_bpca <- t(scaled_spect_complete)
# убеждаемся, что размерность правильная
dim(ipect_bpca)
```

## Сравнение результатов импутации разными методами.

В даном случае, у нас есть полные исходные данные, поэтому мы можем для интереса проверить, какой из методов импутации дал наилучший результат. В качестве меры ошибки мы посчитаем корень из средней суммы квадратов отклонений исходных полных данных и восстановленных. Эта величина называется _root mean squared deviation_ и используется, например, для оценки качества предсказаний разных линейных моделей.

$RMSE = \sqrt{\frac {\sum_{i = 1}^n(y_{1,i} - y_{2,i})^2} {n}}$,

где $y_{1,i}$ и $y_{2,i}$ --- сравниваемые величины. Например, предсказанные моделью и наблюдаемые значения. А в нашем случае истинные и импутированные значения экспрессии.

Чем меньше значение RMSE, тем лучше.

Иногда величину RMSE нормализуют --- делят либо на среднее значение, либо на диапазон значений. Полученная величина называется _normalized RMSE_(NRMSE). Нормализация позволяет сравнивать NRMSE для данных, измеренных в разных единицах.

$NRMSE = \frac {RMSE} {y_{max} - y_{min}}$,

Мы напишем функцию для рассчета RMSE

```{r}
RMSE <- function (act, imp, norm = FALSE){
  act <- as.matrix(act)
  imp <- as.matrix(imp)
  max_val <- max(rbind(act, imp))
  min_val <- min(rbind(act, imp))
  res <- sqrt(sum((act - imp)^2) / nrow(act))
  if (norm == TRUE) res <- res / (max_val - min_val)
  return(res)
}
```

Заметьте, чтобы на самом деле адекватно оценить качество работы разных алгоритмов импутации, нужно повторить всю процедуру, включая генерацию `NA`, много много раз --- сделать бутстреп --- здесь мы сделаем только грубую оценку.

```{r}
# замена средним
RMSE(pecten, ipect_mean)
RMSE(pecten, ipect_mean, norm = TRUE)

# замена средним по k-ближайшим соседям
RMSE(pecten, ipect_knn)
RMSE(pecten, ipect_knn, norm = TRUE)

# BPCA
RMSE(pecten, ipect_bpca)
RMSE(pecten, ipect_bpca, norm = TRUE)
```


# Нормализация и трансформация данных

Нормализация --- очень важный этап подготовки данных. Возможно, вы получите уже нормализованные данные из программы анализа гелей. 

Но исходные данные в нашем примере в датасете `pecten` не нормализованы. Это можно видеть на боксплоте.

```{r}
# создаем палитру и вектор цветов
library(RColorBrewer)
pal <- brewer.pal(9, "Set1")
cols <- pal[pecten.fac$Condition]
# боксплот
boxplot(pecten, outline = FALSE, notch = T, col = cols, main = "Исходные данные")
legend("topright", levels(pecten.fac$Condition), fill = brewer.pal(9, "Set1"), bty = "n", xpd = T)
```

Для того, чтобы выровнять форму распределений применяют квантильную нормализацию

Во время квантильной нормализации двух и более распределений значения переменных сначала сортируют. Затем, исходные значения одинакового ранга заменяют их средними значениями. Так, например, максимальные значения переменных станут средним максимальных значений и так далее.

Рассмотрим, что происходит при квантильной нормализации, на игрушечном примере.

Вот "матрица экспрессии":

```{r}
mat <- matrix(c(1, 7, 2, 10, 6, 3, 1, 4, 4, 7, 9, 2), ncol = 3)
rownames(mat) <- paste0("spot", 1:4)
colnames(mat) <- LETTERS[1:3]
mat
boxplot(mat)
```

Если ранжировать значения каждой из переменных, то матрица рангов будет выглядеть так:

```{r}
ranks <- apply(mat, 2, rank)
ranks
```

Теперь нужно переставить значения в каждой из переменных в порядке, заданном их рангами. Если это сделать с переменной A (первый столбец), получится

```{r}
mat[ranks[, 1], 1]
```

А вот и вся ранжированная матрица

```{r}
ranked_mat <- apply(mat, 2, function(x) x[order(x)])
ranked_mat
```

На следующем этапе нужно посчитать среднее значение для каждой  из строк --- "цену" каждого ранга.

```{r}
value <- rowMeans(ranked_mat)
value
```

Теперь эти "цены рангов" можно подставить вместо рангов в исходную матрицу. Если это сделать с первым столбцом, то получится

```{r}
value[ranks[, 1]]
```

Подставляем цены рангов вместо рангов во всю исходную матрицу

```{r}
norm_mat <- apply(ranks, 2, function(x) value[x])
norm_mat
```

После нормализации форма распределения всех переменных выравнялась.

```{r}
boxplot(norm_mat)
```

Теперь давайте применим квантильную нормализацию к данным о протеоме гребешков.

```{r}
library(limma)
pecten_norm <- normalizeQuantiles(pecten)
boxplot(pecten_norm, outline = FALSE, boxwex = 0.7, notch = T, col = cols, main = "Нормализованные данные")
legend("topright", levels(pecten.fac$Condition), fill = pal, bty = "n", xpd = T)
```

После нормализации размах варьирования величин экспрессии в разных образцах выровнялся, но распределение по-прежнему асимметрично.

Для того чтобы статистические тесты лучше работали, нужно сделать распределение данных более симметричным и похожим на нормальное. Для этого мы должны логарифмировать данные.

Обычно логарифмируют по основанию 2. С логарифмами по основанию 2 принято работать из-за удобства вычислений (числа получаются меньше по абсолютной величине) и удобства интерпретации (если мы считаем разницу логарифмов экспрессии в опыте и контроле и она равна единице, то это означает, что экспрессия различается в два раза).

Если в ваших исходных данных есть нули, то можно перед логарифмированием прибавить к ним небольшую константу, чтобы не получить `-Inf`. Т.е. преборазовать `log2(x + 1)`.

```{r, message=FALSE, warning=FALSE}
pecten_log <- log2(pecten_norm)
boxplot(pecten_log, outline = FALSE, boxwex = 0.7, notch = T, col = cols, main = "Логарифмированные\nнормализованные данные")
legend("topright", levels(pecten.fac$Condition), fill = pal, bty = "n", xpd = T)
```

После нормализации и логарифмирования распределение стало симметричным и приблизительно одинаковым во всех образцах --- с данными можно работать дальше.

# RI-plot (MA-plot)

MA-plot (Mean--Average plot) был изобретен для контроля качества данных экспрессии [@dudoit_comparison_2002]. Для протеомики он был адаптирован немного позднее и получил название RI-plot (Ratio--Intensity plot)[@meunier_data_2005].

Сначала разберемся, как устроен MA-plot на примере исходных данных.

```{r}
X1 <- pecten[, 1:6]
X2 <- pecten[, 7:12]
R <- log2(rowMeans(X2) / rowMeans(X1))
I <- log10(rowMeans(X2) * rowMeans(X1))
```

- R --- это разница уровней экспрессии в образцах
- I --- это средний уровень экспрессии во множестве образцов

```{r}
plot(I, R, main = "Raw data", pch = 21, xlab = "Intensity", ylab = "Ratio")
abline(h = 0)
```

По графику RI-plot можно оценить качество данных.

- Можно оценить наличие выбросов, отскакивающих значений.
- По наличию паттернов можно определить, нужно ли преобразовывать данные. Увеличивающийся разброс значений или искривленный график говорит о плохой нормализации.

На графике исходных данных видно, (1) чем больше уровень экспрессии, тем больше разброс различий ; (2) график искривлен --- это видно по положению плотной массы точек в центре.

После нормализации проблемы практически исчезнут.

```{r}
X1 <- pecten_norm[, 1:6]
X2 <- pecten_norm[, 7:12]
R <- log2(rowMeans(X2) / rowMeans(X1))
I <- log10(rowMeans(X2) * rowMeans(X1))
plot(I, R, main = "Normalized data", pch = 21, xlab = "Intensity", ylab = "Ratio")
abline(h = 0)
```

В пакете `prot2D` `r citep(citation("prot2D"))` есть специальная функция `RIplot()`

```{r, fig.show='animate'}
RIplot(pecten, n1 = 6, n2 = 6, main = "Raw data")
RIplot(pecten_norm, n1 = 6, n2 = 6, main = "Normalized data")
```

## Боремся с оверплотингом (overplotting)

У приведенных выше графиков есть неприятные свойства --- из-за того, что много точек данных 1) они накладываются друг на друга; 2) график долго рисуется, большой объем векторного файла при сохранении. Можно усовершенствовать график одним из способов.

Для решения первой проблемы --- если вас волнует лишь наложение точек, но не волнует объем файла --- можно сделать точки полупрозрачными.

```{r}
# 1) График с полупрозрачными точками на светлом фоне
# Генерируем полупрозрачные цвета
col_btransp <- adjustcolor("darkgreen", alpha.f = 0.2)
plot(I, R, main = "Normalized data,\ntransparent markers", pch = 19, cex = 1.2, xlab = "Intensity", ylab = "Ratio", col = col_btransp)
abline(h = 0)
```

Второй вариант, при помощи цвета точек показать плотность их распределения. Чтобы выбросы были заметнее, можно сделать график на темном фоне. Подробнее о графических настройках `par()` можно посмотреть в файле справки ?`graphical parameters`.

Мы будем использовать [Брюеровскую](https://en.wikipedia.org/wiki/Cynthia_Brewer) 
[@harrower_colorbrewer._2003] желто-зеленую палитру из пакета `RColorBrewer` `r citep(citation("RColorBrewer"))`.

```{r fig.show='hold'}
# Генерируем цвета
library(RColorBrewer)
ramp_ylgn <- colorRampPalette(brewer.pal(9,"YlGn")[-1])
col_density <- densCols(I, R, colramp = ramp_ylgn)
# Цвет фона, осей и пр.
op <- par(bg="black", fg="white", col.axis="white", col.lab="white", col.sub="white", col.main="white")
plot(I, R, col = col_density, pch = 19, cex = 0.5, main = 'Normalized data,\ncolour reflects density')
abline(h = 0)
par(op)
```

Чтобы решить вторую проблему --- если важно уменьшить объем файла --- можно визуализировать число точек внутри гексагональных ячеек при помощи пакета `hexbin` `r citep(citation("hexbin"))`. Подробнее о настройках можно посмотреть в справке `?gplot.hexbin`

```{r fig.show='hold'}
library(hexbin)
binned <- hexbin(cbind(I,R), xbins=30)
plot(binned, colramp = ramp_ylgn,
main='Normalized data,\nhexagonal binning', xlab = "Intensity", ylab = "Ratio", legend = 1)
```

<!-- # Поиск выбросов. -->

# Сохранение графиков в R


```{r, eval=FALSE}
# Создаем директорию для картинок, чтобы не захламлять рабочую директорию. В данном случае, используем относительный путь.
dir.create(file.path("./figs"))

# pdf нужны размеры в дюймах
library(grid)
wid <- convertX(unit(12, "cm"), "inches")
hei <- convertY(unit(8, "cm"), "inches")

pdf("figs/f1.pdf", width = wid, height = hei, bg = "white", paper = "special", onefile = FALSE)
op <- par(cex = 0.6)
plot(I, R, main = "Normalized data", pch = 19, xlab = "Intensity", ylab = "Ratio", col = col_btransp)
abline(h = 0)
par(op)
dev.off()
# можем встроить шрифты
embedFonts(file = "figs/f1.pdf", outfile = "figs/f1emb.pdf")

# png сам умеет переводить единицы длины-ширины.
png("figs/f1.png", width = 12, height = 8, units = "cm", res = 300, type = "cairo-png")
op <- par(cex = 0.6)
plot(I, R, main = "Normalized data", pch = 19, xlab = "Intensity", ylab = "Ratio", col = col_btransp)
abline(h = 0)
par(op)
dev.off()
```


# `ExpressionSet` Objects

Результаты измерения интенсивности пятен на гелях обычно записываются в виде нескольких таблиц:

- Данные об интенсивности пятен --- таблица $p \times n$, где _n_ гелей записаны в столбцах, а интенсивности _p_ пептидов в строках.
- Данные о пробах --- таблица $n \times q$, в которой содержится информация о _q_ свойствах проб (об экспериментальных факторах, повторностях).
- Данные о пептидах --- таблица $p \times r$, в которой описаны _r_ свойств пептидов (например, тривиальное название, функция).
- Данные об эксперименте в целом --- список произвольной длины, в котором содержатся свойства эксперимента и их значения (например, информация об экспериментальном объекте, имя экспериментатора, ссылка на публикацию и т.п.).

Класс `ExpressionSet` разработан специально для того, чтобы хранить данные из этих нескольких таблиц вместе. Многие пакеты с `Bioconductor` работают с данными в этом формате. Объекты `ExpressionSet` понадобятся нам позже для анализа дифференциальной экспрессии 
при помощи пакета `limma` `r citep(citation("limma"))`.

![Объект ExpressionSet](images/ExpressionSet.png)

## Создаем `ExpressionSet` вручную

Давайте научимся создавать самостоятельно объекты `ExpressionSet`. Чтобы работать с этим классом объектов нам понадобятся функции из пакета `Biobase` с `Bioconductor`. 

```{r, message=FALSE, warning=FALSE}
library(Biobase)
```

Для создания `ExpressionSet` нам понадобится несколько вещей:

- Во-первых, данные об интенсивности пятен. Это просто наши (нормализованные) данные интенсивности пятен.

```{r}
expr_data <- as.matrix(pecten_log)
```

- Во-вторых, данные о пробах. Это аннотированный датафрейм (`AnnotatedDataFrame`), который состоит из двух частей: датафрейм с экспериментальными факторами, информацией о повторностях и т.п., а так же метаданные, в которых записаны расшифровки названий факторов. Подробнее см. в справке `?AnnotatedDataFrame`

```{r}
pheno_data <- pecten.fac
pheno_metadata <- data.frame(
  labelDescription = c("Experimental condition"), 
  row.names=c("Condition"))
pheno_data <- new("AnnotatedDataFrame", 
                 data = pheno_data, 
                 varMetadata = pheno_metadata)
```

- В-третьих, данные о пептидах, если они есть. В данном случае, у нас нет никакой информации о пептидах в датасете о гребешках, хотя обычно такая информация бывает (появляется после MS/MS анализа пятен). Поэтому давайте сейчас в качестве тренировки создадим таблицу с данными о пептидах с единственной переменной --- номерами пятен. Имена строк в этой таблице должны совпадать с именами строк в данных об интенсивности пятен в `expr_data`.

```{r}
feature_data <- data.frame(Spot = rownames(pecten_norm))
rownames(feature_data) <- rownames(expr_data)
feature_metadata <- data.frame(
  labelDescription = c("Spot number"),
  row.names = c("Spot"))
f_data <- new("AnnotatedDataFrame", 
              data = feature_data, 
              varMetadata = feature_metadata)
```

- В-четвертых, данные о самом эксперименте. Их особенно важно добавить, если вы вдруг собираетесь делиться данными с кем-то. Данные об эксперименте для включения в `ExpressionSet` должны записаны в объект класса `MIAME`. В файле справки по этому объекту описаны названия и содержание полей (`?MIAME`). Мы заполним только некоторые для примера.

```{r}
experiment_data <-
  new("MIAME",
      name="Sebastien Artigaud et al.",
      lab="lab",
      contact="email@domain.com",
      title="Identifying differentially expressed proteins in two-dimensional electrophoresis experiments: inputs from transcriptomics statistical tools.",
      abstract="Abstract",
      other=list(notes="dataset from prot2D package"))
```

Наконец, когда у нас есть все четыре элемента (на самом деле, достаточно минимум данных об интенсивности пятен), мы можем собрать из них `EspressionSet`. Подробнее см. в справке `?ExpressionSet`

```{r}
eset <-
  ExpressionSet(assayData = expr_data,
                phenoData = pheno_data,
                featureData = f_data,
                experimentData = experiment_data)
```


## Операции с `ExpressionSet` объектами.


```{r}
class(eset)
eset # то же самое, что print(eset)
```

Извлекаем данные о пробах

```{r}
pData(eset)
phenoData(eset)$Condition
phenoData(eset)
```

Названия факторов

```{r}
varLabels(eset)
```

Информация о факторах (более длинное имя, например, если есть)

```{r}
varMetadata(eset)
```

Можно, например, посчитать, сколько в каждой группе было образцов при помощи функции `table()`

```{r}
table(eset$Condition)
```

Можно извлечь информацию о пептидах. В данном случае ее нет - просто номера пятен.

```{r}
head(fData(eset))
fvarLabels(eset)
featureData(eset)
```

Извлечение данных экспрессии

```{r}
# exprs(eset) # полностью
exprs(eset)[1:5,1:3]
```

Создание сабсетов

```{r}
dim(eset)
sub_15 <- eset[, eset$Condition == "15C"]
dim(sub_15)
```


# Сохранение файлов с данными в R

```{r, eval=FALSE}
write.table(pecten_log, file = "data/pecten_log2_normalized.csv", sep = "\t")
```

```{r, eval=FALSE}
save(eset, file = "data/pecten_eset.RData")
```

# Ссылки

```{r include=FALSE}
write.bibtex(file="bibs/02_packages.bib")
```
